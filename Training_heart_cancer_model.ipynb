{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed766ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nibabel\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.color import gray2rgb\n",
    "from cv2 import bitwise_and, addWeighted\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from skimage.exposure import rescale_intensity\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4faaaa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'E:/Task02_Heart/'\n",
    "# downsample by half of the resolution in 2d \n",
    "image_rows = 320//2\n",
    "image_cols = 320//2\n",
    "Num_Classes = 3 # { 0 -> background, 1 -> heart, 2 -> tumour}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e538d298",
   "metadata": {},
   "source": [
    "# loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0e423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainImages_data_path = os.path.join(data_path, 'imagesTr')\n",
    "TrainMasks_data_path = os.path.join(data_path, 'labelsTr')\n",
    "file_list = os.listdir(TrainImages_data_path)\n",
    "imgs_train = []\n",
    "masks_train = []\n",
    "for file_name in file_list:\n",
    "    training_mask = nibabel.load(os.path.join(TrainImages_data_path,file_name))\n",
    "    training_image = nibabel.load(os.path.join(TrainMasks_data_path,file_name))\n",
    "    for k in range(training_mask.shape[2]):\n",
    "        # take the axial cut at z=k plane (xy plane @ k=0,1,...,N) as numpy ndarray\n",
    "        # downsample each image (slice) by helf, i.e. take every second pixel lengthwise and widthwise of the image\n",
    "        # resize each image to size: (image_rows, image_cols)\n",
    "        mask_2d = training_mask.get_fdata()[::2, ::2, k]\n",
    "        mask_2d = resize(mask_2d, (image_rows, image_cols), preserve_range=True)\n",
    "        image_2d = training_image.get_fdata()[::2, ::2, k]\n",
    "        image_2d = resize(image_2d, (image_rows, image_cols), preserve_range=True)\n",
    "        # if mask_2d contains only one gray level (only '0' values, i.e. black image), it means that there is no mask (organ+tumor)\n",
    "        if len(np.unique(mask_2d)) != 1:\n",
    "             masks_train.append(mask_2d)\n",
    "             imgs_train.append(image_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30fe4559",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.ndarray(\n",
    "            (len(imgs_train), image_rows, image_cols), dtype=np.uint8\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ff528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_mask = np.ndarray(\n",
    "            (len(masks_train), image_rows, image_cols), dtype=np.uint8\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c475f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, img in enumerate(imgs_train):\n",
    "        imgs[index, :, :] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e05029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, mask in enumerate(masks_train):\n",
    "        imgs_mask[index, :, :] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdfb0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('HrtImgs_train.npy', imgs)\n",
    "np.save('HrtLbls_train.npy', imgs_mask)\n",
    "# saved the training data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac24644",
   "metadata": {},
   "source": [
    "# load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d889635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    imgs_train = np.load('LvrImgs_train.npy')\n",
    "    masks_train = np.load('LvrLbls_train.npy')\n",
    "    return imgs_train, masks_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b76142c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86fb48f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dice_coef(y_true, y_pred, smooth=1e-7):\n",
    "    '''\n",
    "    Dice coefficient for num_classes labels (classes). Ignores background pixel label 0\n",
    "    Pass to model as metric during compile statement\n",
    "    '''\n",
    "    y_true_f = K.flatten(K.one_hot(K.cast(y_true, 'int32'), num_classes = Num_Classes)[...,1:])\n",
    "    y_pred_f = K.flatten(y_pred[...,1:])\n",
    "    intersect = K.sum(y_true_f * y_pred_f, axis=-1)\n",
    "    denom = K.sum(y_true_f + y_pred_f, axis=-1)\n",
    "    return K.mean((2. * intersect / (denom + smooth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81535f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dice_coef_loss(y_true, y_pred):\n",
    "    '''\n",
    "    Dice loss to minimize. Pass to model as loss during compile statement\n",
    "    '''\n",
    "    return 1 - gen_dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb8a94",
   "metadata": {},
   "source": [
    "# creating a unet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2ea77cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((image_rows, image_cols, 1))\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "PredictedMask = Conv2D(Num_Classes, (1, 1), activation='sigmoid')(conv9)\n",
    "    # last layer is the predicted mask/label image (organ+tumor), each pixel in the set {0,1}\n",
    "    \n",
    "model = Model(inputs=[inputs], outputs=[PredictedMask])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss=gen_dice_coef_loss, metrics=[gen_dice_coef])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90968713",
   "metadata": {},
   "source": [
    "# proceeding to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da061127",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train, imgs_mask_train = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "902b547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train = imgs_train[..., np.newaxis]\n",
    "imgs_mask_train = imgs_mask_train[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ceb634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train = imgs_train.astype('float32')\n",
    "mean = np.mean(imgs_train)\n",
    "std = np.std(imgs_train)\n",
    "imgs_train -= mean\n",
    "imgs_train /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56e43ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_mask_train = imgs_mask_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3aacf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('weights_heart.h5', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d585f7",
   "metadata": {},
   "source": [
    "imgs_train, imgs_test, imgs_mask_train, imgs_mask_test = train_test_split(imgs_train,imgs_mask_train,shuffle = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d9111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/57 [====>.........................] - ETA: 5:21 - loss: 1.0000 - gen_dice_coef: 0.0000e+00"
     ]
    }
   ],
   "source": [
    " history=model.fit(imgs_train, imgs_mask_train, verbose=1, shuffle=True,\n",
    "              validation_split=0.2,\n",
    "              callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13016916",
   "metadata": {},
   "source": [
    "model.evaluate(imgs_test, imgs_mask_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a887f179",
   "metadata": {},
   "source": [
    "# testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e136c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestImages_data_path = os.path.join(data_path, 'imagesTs')\n",
    "file_list = os.listdir(TestImages_data_path)\n",
    "imgs_test = []\n",
    "for file_name in file_list:\n",
    "    img = nibabel.load(os.path.join(TestImages_data_path,file_name))\n",
    "    for k in range(img.shape[2]):\n",
    "        img_2d = np.array(img.get_fdata()[::2, ::2, k])\n",
    "        img_2d = resize(img_2d, (image_rows, image_cols), preserve_range=True)\n",
    "        imgs_test.append(img_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a6c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgst = np.ndarray(\n",
    "            (len(imgs_test), image_rows, image_cols), dtype=np.uint8\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, imge in enumerate(imgs_test):\n",
    "    imgst[index, :, :] = imge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7220be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    " np.save('HrtImgs_test.npy', imgst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ac01fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    imgs_test = np.load('HrtImgs_test.npy')\n",
    "    return imgs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bef528",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_test = load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce763505",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_test = imgs_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_test = imgs_test.astype('float32')\n",
    "mean = np.mean(imgs_test)\n",
    "std = np.std(imgs_test)\n",
    "imgs_test -= mean\n",
    "imgs_test /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d76d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights_heart.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b786f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_mask_test = model.predict(imgs_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5448e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Predicted_HrtMasks.npy', imgs_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dir = 'Predicted_Heart_Masks'\n",
    "if not os.path.exists(pred_dir):\n",
    "    os.mkdir(pred_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8491e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(imgs_test)):        \n",
    "        pred_mask = model.predict(imgs_test[k,:,:,:][np.newaxis,...])   # shape: (1, 256, 256, 3)\n",
    "        pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "        pred_mask = pred_mask[..., tf.newaxis]\n",
    "        pred_mask = pred_mask[0]\n",
    "        pred_mask = tf.keras.preprocessing.image.array_to_img(pred_mask)\n",
    "        pred_mask = tf.keras.preprocessing.image.img_to_array(pred_mask)[:,:,0]\n",
    "        mask = pred_mask.astype('uint8')\n",
    "\n",
    "        testImg = rescale_intensity(imgs_test[k,:,:,0], out_range=(0,255))\n",
    "        testImg = testImg.astype('uint8')\n",
    "        testImgRGB = gray2rgb(testImg)\n",
    "\n",
    "        blueImg = np.zeros(testImgRGB.shape, testImgRGB.dtype)\n",
    "        blueImg[:,:] = (0, 0, 255)\n",
    "        blueMask = bitwise_and(blueImg, blueImg, mask = mask)\n",
    "        blendos = addWeighted(blueMask, 1, testImgRGB, 1, 0)\n",
    "        sgmntdImg = mark_boundaries(blendos, mask, color = (0.8, 0.5, 0.38))\n",
    "        imsave(os.path.join(pred_dir, str(k) + '_pred.png'), sgmntdImg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a5181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImgsNames = sorted(os.listdir(pred_dir), key=len)\n",
    "ImgsNames = ImgsNames[2513:2597:]\n",
    "Imgs = []\n",
    "for image_name in ImgsNames:\n",
    "    Imgs.append(imageio.imread(os.path.join(pred_dir,image_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3617f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "List = [0.1]*len(ImgsNames)\n",
    "List[13] = 1\n",
    "imageio.mimwrite('animated_heart.gif', Imgs, duration = List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68884ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['gen_dice_coef'])\n",
    "plt.plot(history.history['val_gen_dice_coef'])\n",
    "plt.title('Generalized Dice Coefficient (Liver)')\n",
    "plt.ylabel('Dice Coeff')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a57bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Generalized Dice Loss (Liver)')\n",
    "plt.ylabel('Dice Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
